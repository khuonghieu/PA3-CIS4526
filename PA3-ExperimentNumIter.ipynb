{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(train_y, pred_y):\n",
    "    innerProduct = np.multiply(train_y, pred_y)\n",
    "    log_loss = np.log(1 + np.exp(-innerProduct))\n",
    "    return np.mean(log_loss)\n",
    "\n",
    "\n",
    "def hinge_loss(train_y, pred_y):\n",
    "    innerProduct = np.multiply(train_y, pred_y)\n",
    "    hinge_loss_vector = np.maximum(0,1-innerProduct)\n",
    "    return np.mean(hinge_loss_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all the values of the weight\n",
    "def l1_reg(w):\n",
    "    l1_reg_loss = 0;\n",
    "    for i in range(1,len(w)):\n",
    "        l1_reg_loss += abs(w[i])\n",
    "    return l1_reg_loss\n",
    "\n",
    "#Dot product of the weight with itself\n",
    "def l2_reg(w):    \n",
    "    l2_reg_loss = np.dot(w[1:], np.transpose(w[1:]))\n",
    "    return l2_reg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(train_x, train_y, learn_rate, loss, num_iteration, lambda_val=None, regularizer=None):\n",
    "    #Initialize weight with bias\n",
    "    weight_vector = np.random.rand(len(train_x[0]) + 1) \n",
    "    #Iteration\n",
    "    num_iters = num_iteration\n",
    "    #Numerical_differentiation, as suggested\n",
    "    h = 0.0001\n",
    "    #Run for num_iters times\n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        current_weight = np.copy(weight_vector)\n",
    "        #Delta_weight for updating: w = w - learn_rate*delta_weight\n",
    "        delta_weight = np.zeros(len(train_x[0]) + 1) \n",
    "        #Prediction using current weight\n",
    "        predict_y = test_classifier(current_weight,train_x)\n",
    "        \n",
    "        #Check for lambda existence, if yes then add regularization\n",
    "        if(lambda_val):\n",
    "            current_loss = loss(train_y, predict_y) + lambda_val*regularizer(current_weight)\n",
    "        else:\n",
    "            current_loss = loss(train_y, predict_y)\n",
    "            \n",
    "        \n",
    "        for i in range(len(delta_weight)):\n",
    "            tmp_current_weight = np.copy(current_weight)\n",
    "            tmp_current_weight[i] = tmp_current_weight[i] + h;\n",
    "            \n",
    "            tmp_predict_y = test_classifier(tmp_current_weight,train_x)\n",
    "            \n",
    "            # Find delta_weight using loss function\n",
    "            \n",
    "            #Check for lambda existence\n",
    "            if(lambda_val):\n",
    "                tmp_loss = loss(train_y, tmp_predict_y) + lambda_val*regularizer(tmp_current_weight)\n",
    "            else:\n",
    "                tmp_loss = loss(train_y, tmp_predict_y)\n",
    "            \n",
    "            #Differentiation\n",
    "            delta_weight[i] = (tmp_loss - current_loss) / h\n",
    "\n",
    "        #Update weight\n",
    "        weight_vector = current_weight - learn_rate*delta_weight\n",
    "           \n",
    "    return weight_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return pred_y as inner product of weights and feature values\n",
    "def test_classifier(w, test_x):\n",
    "    pred_y = np.zeros(len(test_x))\n",
    "    for i in range(len(test_x)):\n",
    "        pred_y[i] = np.dot(w[1:], test_x[i]) + w[0]\n",
    "    return pred_y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(trainX,testX):\n",
    "    # Standardize the dataset\n",
    "    dataX_trans = trainX.transpose()\n",
    "    column = 0\n",
    "    for row in dataX_trans:\n",
    "        #Subtract mean from every value, then divide by deviation\n",
    "        mean = np.mean(row)\n",
    "        std = np.std(row)\n",
    "        for i in range(len(dataX_trans[0])):\n",
    "            trainX[i][column] -= mean\n",
    "            trainX[i][column] /= std\n",
    "        for i in range(len(testX.transpose()[0])):\n",
    "            testX[i][column] -= mean\n",
    "            testX[i][column] /= std\n",
    "        column += 1\n",
    "\n",
    "#Find accuracy\n",
    "def compute_accuracy(test_y, pred_y):\n",
    "    #Convert predicted label into -1 and 1\n",
    "    convert_pred_y = np.copy(pred_y)\n",
    "    for j in range(len(convert_pred_y)):\n",
    "        if(convert_pred_y[j] < 6):\n",
    "            convert_pred_y[j] = -1\n",
    "        elif (convert_pred_y[j] > 6):\n",
    "            convert_pred_y[j] = 1\n",
    "    #Vector filled with booleans\n",
    "    compare = (test_y == convert_pred_y)\n",
    "    match_count = 0\n",
    "    for i in range(len(compare)):\n",
    "        if (compare[i] == True):\n",
    "            match_count += 1 \n",
    "    \n",
    "    return (match_count/len(test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ,learn rate 0.01 ,iter num 20\n",
      "Accuracy 0.5648148148148148\n",
      "\n",
      "Logistic Regression ,learn rate 0.01 ,iter num 40\n",
      "Accuracy 0.44037037037037036\n",
      "\n",
      "Logistic Regression ,learn rate 0.01 ,iter num 60\n",
      "Accuracy 0.5662962962962963\n",
      "\n",
      "Logistic Regression ,learn rate 0.01 ,iter num 80\n",
      "Accuracy 0.4622222222222222\n",
      "\n",
      "Logistic Regression ,learn rate 0.01 ,iter num 100\n",
      "Accuracy 0.5407407407407407\n",
      "\n",
      "Logistic Regression ,learn rate 0.01 ,iter num 120\n",
      "Accuracy 0.5207407407407407\n",
      "\n",
      "Logistic Regression ,learn rate 0.01 ,iter num 140\n",
      "Accuracy 0.6103703703703703\n",
      "\n",
      "Logistic Regression ,learn rate 0.01 ,iter num 160\n",
      "Accuracy 0.4644444444444444\n",
      "\n",
      "Logistic Regression ,learn rate 0.01 ,iter num 180\n",
      "Accuracy 0.5285185185185185\n",
      "\n",
      "Logistic Regression ,learn rate 0.01 ,iter num 200\n",
      "Accuracy 0.48592592592592593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    # Read the training data file\n",
    "    szDatasetPath = 'winequality-white.csv'\n",
    "    listClasses = []\n",
    "    listAttrs = []\n",
    "    bFirstRow = True\n",
    "    with open(szDatasetPath) as csvFile:\n",
    "        csvReader = csv.reader(csvFile, delimiter=',')\n",
    "        for row in csvReader:\n",
    "            if bFirstRow:\n",
    "                bFirstRow = False\n",
    "                continue\n",
    "            if int(row[-1]) < 6:\n",
    "                listClasses.append(-1)\n",
    "                listAttrs.append(list(map(float, row[1:len(row) - 1])))\n",
    "            elif int(row[-1]) > 6:\n",
    "                listClasses.append(+1)\n",
    "                listAttrs.append(list(map(float, row[1:len(row) - 1])))\n",
    "    dataX = np.array(listAttrs)\n",
    "    dataY = np.array(listClasses)\n",
    "    \n",
    "    # 5-fold cross-validation\n",
    "    np.set_printoptions(precision=8)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    subsetNum = int((len(dataX)/5))\n",
    "    \n",
    "    \n",
    "    #Fold 5 times, split the train and test sets\n",
    "    acc_svm_avg=0\n",
    "    \n",
    "    \n",
    "    iterNumArr = [20,40,60,80,100,120,140,160,180,200]\n",
    "    for num in iterNumArr:\n",
    "        #Initialize 5-folds\n",
    "        acc_log_avg=0\n",
    "        for i in range(5):\n",
    "            if(i == 0):\n",
    "                #Split\n",
    "                subdataX = np.split(dataX,[subsetNum])\n",
    "                subdataY = np.split(dataY,[subsetNum])\n",
    "                #Train\n",
    "                trainX = subdataX[1]\n",
    "                trainY = subdataY[1]\n",
    "                #Test\n",
    "                testX = subdataX[0]\n",
    "                testY = subdataY[0]\n",
    "            elif(i == 4):\n",
    "                #Split\n",
    "                subdataX = np.split(dataX,[subsetNum*i])\n",
    "                subdataY = np.split(dataY,[subsetNum*i])\n",
    "                #Train\n",
    "                trainX = subdataX[0]\n",
    "                trainY = subdataY[0]\n",
    "                #Test\n",
    "                testX = subdataX[1]\n",
    "                testY = subdataY[1]\n",
    "            else:\n",
    "                #Split\n",
    "                subdataX = np.split(dataX,[subsetNum*i,subsetNum*(i+1)])\n",
    "                subdataY = np.split(dataY,[subsetNum*i,subsetNum*(i+1)])\n",
    "                #Train\n",
    "                trainX = np.concatenate((subdataX[0],subdataX[2]),axis=0)\n",
    "                trainY = np.concatenate((subdataY[0],subdataY[2]),axis=0)\n",
    "                #Test\n",
    "                testX = subdataX[1]\n",
    "                testY = subdataY[1]\n",
    "            #Logistic Regression\n",
    "            weight_vector_log = train_classifier(trainX,trainY,0.01,logistic_loss,num)\n",
    "            pred_y_log = test_classifier(weight_vector_log,testX)\n",
    "            acc_log = compute_accuracy(testY,pred_y_log)\n",
    "            acc_log_avg+=acc_log\n",
    "        print(\"Logistic Regression\",\",learn rate\",0.01,\",iter num\",num)\n",
    "        print(\"Accuracy\",acc_log_avg/5)\n",
    "        print()\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
